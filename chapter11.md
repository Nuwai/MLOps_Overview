# ğŸ“˜ Chapter 11 â€” ML Pipelines & Orchestration (Airflow, Prefect, Kubeflow)

In modern MLOps, building a model is only **one small part** of the job.  
Data changes, models degrade, and systems must run on **automation**, not manual re-running.

This is where **ML pipelines** and **workflow orchestration** come in.

This chapter covers:

- What ML pipelines are  
- Batch vs real-time pipelines  
- Airflow  
- Prefect  
- Kubeflow  
- Feature stores  
- A full end-to-end training â†’ evaluation â†’ deployment pipeline  
- Best practices  
- Architecture diagrams  
- Real examples used by companies  

---

# ğŸ§  11.1 What Are ML Pipelines?

An ML pipeline is a **series of automated steps** that transform raw data â†’ trained model â†’ deployed system.

Example pipeline:

```
Data Ingestion â†’ Data Validation â†’ Feature Engineering â†’
Training â†’ Evaluation â†’ Model Registry â†’ Deployment
```

Pipelines prevent:
- Manual work  
- Inconsistent results  
- Human errors  
- Non-reproducible workflows  

---

# â±ï¸ 11.2 Batch vs Real-Time Pipelines

## **Batch Pipelines**
Run on a schedule:
- hourly  
- daily  
- weekly  

Examples:
- Daily retrain  
- Batch prediction  
- ETL jobs  

Tools:
- Airflow  
- Prefect  
- Kubeflow  
- AWS Batch  
- GCP Composer  

---

## **Real-time Pipelines**
Triggered by events (streaming).

Examples:
- Fraud detection  
- Recommendation ranking  
- Real-time monitoring  
- Alerts  

Tools:
- Kafka  
- Flink  
- Spark Streaming  
- Kinesis  

---

# ğŸ“ 11.3 Pipeline Example Diagram

```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     Raw Data        â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Data Preprocessing    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   Feature Engineering       â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚      Training          â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     Evaluation           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚     Model Registry        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚        Deployment          â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸš€ 11.4 Tools for ML Orchestration

## **1ï¸âƒ£ Airflow**
- Most widely-used workflow orchestrator  
- DAG-based (Directed Acyclic Graphs)  
- Great for data + ML  
- Scheduling, retry logic, logging, parallelism  

## **2ï¸âƒ£ Prefect**
- Pythonic, developer-friendly  
- Easier than Airflow  
- Cloud UI available  
- Async + dynamic pipelines  

## **3ï¸âƒ£ Kubeflow**
- Kubernetes-native ML pipelines  
- Great for:
  - GPU workloads  
  - Large-scale deep learning  
  - AutoML  
  - Advanced ML workflows  

---

# ğŸ› ï¸ 11.5 Airflow Deep Dive

Airflow defines workflows as **DAGs (Directed Acyclic Graphs)**.

### Install:

```bash
pip install apache-airflow
```

### Example Airflow DAG

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

def train():
    print("Training model...")

def evaluate():
    print("Evaluating...")

with DAG(
    "ml_pipeline",
    start_date=datetime(2023, 1, 1),
    schedule_interval="@daily",
) as dag:

    train_task = PythonOperator(
        task_id="train",
        python_callable=train
    )

    eval_task = PythonOperator(
        task_id="evaluate",
        python_callable=evaluate
    )

    train_task >> eval_task
```

---

# âš™ï¸ 11.6 Prefect Deep Dive

Prefect uses **Flows** and **Tasks**.

Install:

```bash
pip install prefect
```

### Example Prefect Flow

```python
from prefect import task, flow

@task
def extract():
    return [1,2,3]

@task
def train(data):
    return sum(data)

@flow
def pipeline():
    data = extract()
    result = train(data)
    print(result)

pipeline()
```

### Why ML engineers love Prefect:
- Easier debugging  
- Works locally + cloud  
- More flexible than Airflow  

---

# ğŸ¤– 11.7 Kubeflow Pipelines

Kubeflow = Kubernetes-native ML platform.

Supports:
- Scalable training  
- Distributed training  
- GPU/TPU  
- Feature stores  
- Full ML lifecycle  

### Kubeflow pipeline example:

```python
def train_op():
    return dsl.ContainerOp(
        name="train model",
        image="ml-train:latest",
        command=["python", "train.py"]
    )

@dsl.pipeline(name="ml-pipeline")
def pipeline():
    train = train_op()
```

Deploy with:

```bash
kubectl apply -f pipeline.yaml
```

---

# ğŸ§± 11.8 ML Pipelines vs General Workflow Pipelines

| Task | Airflow | Kubeflow |
|------|--------|----------|
| ETL | âœ… | ğŸ”¶ |
| ML | Good | Excellent |
| GPU training | âŒ | âœ… |
| Kubernetes native | âŒ | âœ… |
| Enterprise support | High | Medium |
| Simple setup | Medium | Hard |
| Workflow flexibility | High | Medium |

---

# ğŸ§¬ 11.9 Feature Stores

Feature Store = consistent, validated feature management.

Examples:
- Feast  
- Tecton  
- Hopworks  
- Vertex AI Feature Store  
- SageMaker Feature Store  

### Why use feature stores?

Without them â†’ training uses different features than production.

### With feature store:

```
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Feature Store  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Same features for:      â”‚
            â”‚ - Training              â”‚
            â”‚ - Online inference      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ”„ 11.10 Example End-to-End Pipeline (Full ML Workflow)

This is how real companies automate ML retraining.

### Step 1 â€” Data Ingestion

```python
def ingest():
    df = read_from_s3("dataset.csv")
    return df
```

### Step 2 â€” Validation

```python
validate(df)
```

### Step 3 â€” Feature Engineering

```python
X, y = features(df)
```

### Step 4 â€” Training

```python
model.fit(X, y)
```

### Step 5 â€” Evaluation

```python
metrics = evaluate(model)
```

### Step 6 â€” Register Model (MLflow)

```python
mlflow.log_model(model, "model")
mlflow.register_model(...)
```

### Step 7 â€” Deployment

- Push Docker image  
- CI/CD triggers  
- Kubernetes rolling update  

---

# ğŸ”— 11.11 CI/CD + Pipelines Integration

A hybrid architecture:

```
Git push â†’ GitHub Actions â†’ Build model/Docker â†’ Registry
                               â†“
                         Airflow scheduler â†’ Daily pipeline â†’ Model Registry
                               â†“
                           Deployment â†’ K8s
```

---

# ğŸ›°ï¸ 11.12 Reproducibility With Pipelines

Good pipelines ensure:

- Same environment for training  
- Same data version  
- Same hyperparameters  
- Code version tracking  
- Automatic metadata logging  

Tools:
- MLflow  
- DVC  
- Kubeflow metadata server  

---

# ğŸ“ˆ 11.13 Monitoring Pipelines

Track:

- Task success/failure  
- Task runtime  
- Upstream/downstream dependency failures  
- Retries  
- Alerts  

Tools:
- Airflow UI  
- Prefect Cloud  
- Kubeflow dashboard  

---

# ğŸ§± 11.14 Real-World ML Pipeline Architecture Diagram

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      Data Warehouse       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–¼
                             Data Ingestion
                                    â–¼
                         Data Validation (GX)
                                    â–¼
                         Feature Engineering (Feast)
                                    â–¼
                         Training Jobs (K8s/Batch)
                                    â–¼
                          Evaluation (CI/CD gates)
                                    â–¼
                      Model Registry (MLflow/DVC)
                                    â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                              â–¼
              Batch Deployment              Real-Time Deployment
                    â”‚                              â”‚
            Batch Inference Jobs            FastAPI / gRPC API
```

---

# â— 11.15 Common Pitfalls in ML Pipelines

âŒ Manual retraining  
âŒ Not versioning datasets  
âŒ Pipelines with hidden states  
âŒ Mixing testing + training environments  
âŒ No monitoring for pipeline failures  
âŒ No retry or backoff system  
âŒ No lineage tracking  

---

# ğŸ§ª 11.16 Exercises

### **Exercise 1 â€” Airflow DAG**
Create a DAG with:
- Ingestion  
- Training  
- Evaluation  

### **Exercise 2 â€” Prefect**
Convert your local training script into a Prefect flow.

### **Exercise 3 â€” Kubeflow**
Containerize your training job and run it in a Kubeflow pipeline.

### **Exercise 4 â€” Feature Store**
Define two features for a dataset (one offline, one online).

---

# ğŸ“ 11.17 Summary

- ML pipelines automate the ML lifecycle  
- Airflow â†’ general workflow orchestration  
- Prefect â†’ Pythonic and modern  
- Kubeflow â†’ ML-focused & Kubernetes native  
- Feature stores ensure consistent features  
- Full pipelines handle ingestion â†’ validation â†’ training â†’ registry â†’ deployment  
- Pipelines reduce human error and enable scalability  

---

# ğŸ‰ End of Chapter 11
